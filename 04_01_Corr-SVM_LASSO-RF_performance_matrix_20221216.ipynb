{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Written by Jae Hyon Park, MD, PhD, Jongjin Yoon, MD, PhD.\n",
    "#Department of Radiology, Yonsei University College of Medicine\n",
    "\n",
    "#Radiomics model to predict hepatic metastasis or abscess in periampullary cancer patients \n",
    "# For related questions, please contact the following e-mail: yelv@yuhs.ac (corresponding author: Yong Eun Chung)\n",
    "\n",
    "#Contents:\n",
    "#code: python code for performing the analysis, code may be modified for intended use. \n",
    "#pyradiomics folder: This is an open-source python package for the extraction of Radiomics features from medical imaging. With this package we aim to establish a reference standard for Radiomic Analysis, and provide a tested and maintained open-source platform for easy and reproducible Radiomic Feature extraction (https://pyradiomics.readthedocs.io/en/latest/). A used version of the radiomics tool used in this study, pyradiomics, is included.\n",
    "#Slicer folder: 3D Slicer is a free, open source and multi-platform software package widely used for medical, biomedical, and related imaging research (https://www.slicer.org/).\n",
    "\n",
    "\n",
    "# Import common modules\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import shutil\n",
    "import sklearn\n",
    "import pingouin as pg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f\n",
    "import tqdm \n",
    "import random\n",
    "import cv2\n",
    "from ReliefF import ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file loading\n",
    "path1 = \"C:/Research/Liver_abscess_metastasis_radiomics/Raw_data/gangnam_shinchon/concat/\"\n",
    "path2 = \"C:/Research/Liver_abscess_metastasis_radiomics/Raw_data/gangnam_shinchon/concat/ICC/\"\n",
    "\n",
    "csv3 = pd.read_csv(os.path.join(path1, filename3), sep=\",\") \n",
    "csv4 = pd.read_csv(os.path.join(path2, filename4), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_train = pd.DataFrame(csv3)\n",
    "labels_df_train = data_df_train[\"target\"]\n",
    "ID_df_train = data_df_train[\"Patient_ID\"]\n",
    "\n",
    "data_df_test = pd.DataFrame(csv4)\n",
    "labels_df_test = data_df_test[\"target\"]\n",
    "ID_df_test = data_df_test[\"Patient_ID\"]\n",
    "\n",
    "csv3 = csv3.drop(columns=['target', 'Patient_ID'], axis=0)\n",
    "csv4 = csv4.drop(columns=['target', 'Patient_ID'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ICC > 0.75 인 feature만 선별\n",
    "good_csv7 = csv7['ICC'] >= 0.75\n",
    "good_csv8 = csv8['ICC'] >= 0.75\n",
    "\n",
    "csv7_filter_df = csv7[good_csv7]\n",
    "csv8_filter_df = csv8[good_csv8]\n",
    "\n",
    "print(csv7_filter_df)\n",
    "print(csv8_filter_df)\n",
    "\n",
    "common_good_features_df_1 = pd.merge(csv7_filter_df, csv8_filter_df, on=\"feature\")\n",
    "\n",
    "print(common_good_features_df_1)\n",
    "\n",
    "common_good_features_list_df_1 = common_good_features_df_1[['feature']]\n",
    "common_good_features_list_1 = common_good_features_list_df_1.values.tolist()\n",
    "common_good_features_list_1.append(['Patient_ID', 'target'])\n",
    "common_good_features_list_1 = sum(common_good_features_list_1, []) # 차원 축소\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                 feature  Type  \\\n",
      "0             1         diagnostics_Image-original_Mean  ICC2   \n",
      "3             1          original_shape_LeastAxisLength  ICC2   \n",
      "5             1  original_shape_Maximum2DDiameterColumn  ICC2   \n",
      "6             1     original_shape_Maximum2DDiameterRow  ICC2   \n",
      "9             1               original_shape_MeshVolume  ICC2   \n",
      "..          ...                                     ...   ...   \n",
      "841           1        wavelet-LLL_glszm_ZonePercentage  ICC2   \n",
      "842           1          wavelet-LLL_glszm_ZoneVariance  ICC2   \n",
      "843           1              wavelet-LLL_ngtdm_Busyness  ICC2   \n",
      "844           1            wavelet-LLL_ngtdm_Coarseness  ICC2   \n",
      "845           1            wavelet-LLL_ngtdm_Complexity  ICC2   \n",
      "\n",
      "              Description    ICC             F  df1  df2  pval        CI95%  \n",
      "0    Single random raters  1.000 -7.570308e+15   22   22   1.0      [1. 1.]  \n",
      "3    Single random raters  0.961  6.441900e+01   22   22   0.0  [0.89 0.99]  \n",
      "5    Single random raters  0.942  3.346300e+01   22   22   0.0  [0.87 0.97]  \n",
      "6    Single random raters  0.966  5.950300e+01   22   22   0.0  [0.92 0.99]  \n",
      "9    Single random raters  0.960  5.393700e+01   22   22   0.0  [0.91 0.98]  \n",
      "..                    ...    ...           ...  ...  ...   ...          ...  \n",
      "841  Single random raters  0.961  4.816500e+01   22   22   0.0  [0.91 0.98]  \n",
      "842  Single random raters  0.940  3.128900e+01   22   22   0.0  [0.86 0.97]  \n",
      "843  Single random raters  0.955  4.299700e+01   22   22   0.0  [0.9  0.98]  \n",
      "844  Single random raters  0.991  2.484070e+02   22   22   0.0  [0.98 1.  ]  \n",
      "845  Single random raters  0.901  1.957300e+01   22   22   0.0  [0.78 0.96]  \n",
      "\n",
      "[722 rows x 10 columns]\n",
      "     Unnamed: 0                                 feature  Type  \\\n",
      "0             1         diagnostics_Image-original_Mean  ICC2   \n",
      "2             1                 original_shape_Flatness  ICC2   \n",
      "3             1          original_shape_LeastAxisLength  ICC2   \n",
      "4             1          original_shape_MajorAxisLength  ICC2   \n",
      "5             1  original_shape_Maximum2DDiameterColumn  ICC2   \n",
      "..          ...                                     ...   ...   \n",
      "842           1          wavelet-LLL_glszm_ZoneVariance  ICC2   \n",
      "844           1            wavelet-LLL_ngtdm_Coarseness  ICC2   \n",
      "845           1            wavelet-LLL_ngtdm_Complexity  ICC2   \n",
      "846           1              wavelet-LLL_ngtdm_Contrast  ICC2   \n",
      "847           1              wavelet-LLL_ngtdm_Strength  ICC2   \n",
      "\n",
      "              Description    ICC             F  df1  df2  pval        CI95%  \n",
      "0    Single random raters  1.000  5.734438e+15   30   30   0.0      [1. 1.]  \n",
      "2    Single random raters  0.778  8.721000e+00   30   30   0.0  [0.58 0.89]  \n",
      "3    Single random raters  0.974  7.261700e+01   30   30   0.0  [0.95 0.99]  \n",
      "4    Single random raters  0.974  8.215400e+01   30   30   0.0  [0.94 0.99]  \n",
      "5    Single random raters  0.879  1.824800e+01   30   30   0.0  [0.74 0.94]  \n",
      "..                    ...    ...           ...  ...  ...   ...          ...  \n",
      "842  Single random raters  0.996  4.772020e+02   30   30   0.0  [0.99 1.  ]  \n",
      "844  Single random raters  0.956  4.686100e+01   30   30   0.0  [0.91 0.98]  \n",
      "845  Single random raters  0.911  2.243100e+01   30   30   0.0  [0.82 0.96]  \n",
      "846  Single random raters  0.962  5.054000e+01   30   30   0.0  [0.92 0.98]  \n",
      "847  Single random raters  0.783  8.354000e+00   30   30   0.0  [0.6  0.89]  \n",
      "\n",
      "[788 rows x 10 columns]\n",
      "     Unnamed: 0_x                                 feature Type_x  \\\n",
      "0               1         diagnostics_Image-original_Mean   ICC2   \n",
      "1               1          original_shape_LeastAxisLength   ICC2   \n",
      "2               1  original_shape_Maximum2DDiameterColumn   ICC2   \n",
      "3               1     original_shape_Maximum2DDiameterRow   ICC2   \n",
      "4               1               original_shape_MeshVolume   ICC2   \n",
      "..            ...                                     ...    ...   \n",
      "687             1           wavelet-LLL_glszm_ZoneEntropy   ICC2   \n",
      "688             1        wavelet-LLL_glszm_ZonePercentage   ICC2   \n",
      "689             1          wavelet-LLL_glszm_ZoneVariance   ICC2   \n",
      "690             1            wavelet-LLL_ngtdm_Coarseness   ICC2   \n",
      "691             1            wavelet-LLL_ngtdm_Complexity   ICC2   \n",
      "\n",
      "            Description_x  ICC_x           F_x  df1_x  df2_x  pval_x  \\\n",
      "0    Single random raters  1.000 -7.570308e+15     22     22     1.0   \n",
      "1    Single random raters  0.961  6.441900e+01     22     22     0.0   \n",
      "2    Single random raters  0.942  3.346300e+01     22     22     0.0   \n",
      "3    Single random raters  0.966  5.950300e+01     22     22     0.0   \n",
      "4    Single random raters  0.960  5.393700e+01     22     22     0.0   \n",
      "..                    ...    ...           ...    ...    ...     ...   \n",
      "687  Single random raters  0.940  3.473600e+01     22     22     0.0   \n",
      "688  Single random raters  0.961  4.816500e+01     22     22     0.0   \n",
      "689  Single random raters  0.940  3.128900e+01     22     22     0.0   \n",
      "690  Single random raters  0.991  2.484070e+02     22     22     0.0   \n",
      "691  Single random raters  0.901  1.957300e+01     22     22     0.0   \n",
      "\n",
      "         CI95%_x  Unnamed: 0_y Type_y         Description_y  ICC_y  \\\n",
      "0        [1. 1.]             1   ICC2  Single random raters  1.000   \n",
      "1    [0.89 0.99]             1   ICC2  Single random raters  0.974   \n",
      "2    [0.87 0.97]             1   ICC2  Single random raters  0.879   \n",
      "3    [0.92 0.99]             1   ICC2  Single random raters  0.907   \n",
      "4    [0.91 0.98]             1   ICC2  Single random raters  0.983   \n",
      "..           ...           ...    ...                   ...    ...   \n",
      "687  [0.86 0.97]             1   ICC2  Single random raters  0.858   \n",
      "688  [0.91 0.98]             1   ICC2  Single random raters  0.981   \n",
      "689  [0.86 0.97]             1   ICC2  Single random raters  0.996   \n",
      "690  [0.98 1.  ]             1   ICC2  Single random raters  0.956   \n",
      "691  [0.78 0.96]             1   ICC2  Single random raters  0.911   \n",
      "\n",
      "              F_y  df1_y  df2_y  pval_y      CI95%_y  \n",
      "0    5.734438e+15     30     30     0.0      [1. 1.]  \n",
      "1    7.261700e+01     30     30     0.0  [0.95 0.99]  \n",
      "2    1.824800e+01     30     30     0.0  [0.74 0.94]  \n",
      "3    2.410900e+01     30     30     0.0  [0.79 0.96]  \n",
      "4    1.239560e+02     30     30     0.0  [0.97 0.99]  \n",
      "..            ...    ...    ...     ...          ...  \n",
      "687  1.394700e+01     30     30     0.0  [0.72 0.93]  \n",
      "688  1.044340e+02     30     30     0.0  [0.96 0.99]  \n",
      "689  4.772020e+02     30     30     0.0  [0.99 1.  ]  \n",
      "690  4.686100e+01     30     30     0.0  [0.91 0.98]  \n",
      "691  2.243100e+01     30     30     0.0  [0.82 0.96]  \n",
      "\n",
      "[692 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ICC > 0.75 인 feature만 선별\n",
    "good_csv9 = csv9['ICC'] >= 0.75\n",
    "good_csv10 = csv10['ICC'] >= 0.75\n",
    "\n",
    "csv9_filter_df = csv9[good_csv9]\n",
    "csv10_filter_df = csv10[good_csv10]\n",
    "\n",
    "print(csv9_filter_df)\n",
    "print(csv10_filter_df)\n",
    "\n",
    "common_good_features_df_2 = pd.merge(csv9_filter_df, csv10_filter_df, on=\"feature\")\n",
    "\n",
    "print(common_good_features_df_2)\n",
    "\n",
    "common_good_features_list_df_2 = common_good_features_df_2[['feature']]\n",
    "common_good_features_list_2 = common_good_features_list_df_2.values.tolist()\n",
    "common_good_features_list_2.append(['Patient_ID', 'target'])\n",
    "common_good_features_list_2 = sum(common_good_features_list_2, []) # 차원 축소\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                 feature  Type  \\\n",
      "0             1         diagnostics_Image-original_Mean  ICC2   \n",
      "3             1          original_shape_LeastAxisLength  ICC2   \n",
      "5             1  original_shape_Maximum2DDiameterColumn  ICC2   \n",
      "6             1     original_shape_Maximum2DDiameterRow  ICC2   \n",
      "9             1               original_shape_MeshVolume  ICC2   \n",
      "..          ...                                     ...   ...   \n",
      "842           1          wavelet-LLL_glszm_ZoneVariance  ICC2   \n",
      "843           1              wavelet-LLL_ngtdm_Busyness  ICC2   \n",
      "844           1            wavelet-LLL_ngtdm_Coarseness  ICC2   \n",
      "845           1            wavelet-LLL_ngtdm_Complexity  ICC2   \n",
      "847           1              wavelet-LLL_ngtdm_Strength  ICC2   \n",
      "\n",
      "              Description    ICC             F  df1  df2  pval        CI95%  \n",
      "0    Single random raters  1.000  5.095080e+15   22   22   0.0      [1. 1.]  \n",
      "3    Single random raters  0.881  1.609900e+01   22   22   0.0  [0.74 0.95]  \n",
      "5    Single random raters  0.924  2.447200e+01   22   22   0.0  [0.83 0.97]  \n",
      "6    Single random raters  0.941  3.344100e+01   22   22   0.0  [0.87 0.97]  \n",
      "9    Single random raters  0.953  5.058800e+01   22   22   0.0  [0.87 0.98]  \n",
      "..                    ...    ...           ...  ...  ...   ...          ...  \n",
      "842  Single random raters  1.000  7.933035e+05   22   22   0.0      [1. 1.]  \n",
      "843  Single random raters  0.996  5.379530e+02   22   22   0.0  [0.99 1.  ]  \n",
      "844  Single random raters  0.967  5.948800e+01   22   22   0.0  [0.93 0.99]  \n",
      "845  Single random raters  0.987  1.607790e+02   22   22   0.0  [0.97 0.99]  \n",
      "847  Single random raters  0.910  2.040400e+01   22   22   0.0  [0.8  0.96]  \n",
      "\n",
      "[704 rows x 10 columns]\n",
      "     Unnamed: 0                                 feature  Type  \\\n",
      "0             1         diagnostics_Image-original_Mean  ICC2   \n",
      "1             1               original_shape_Elongation  ICC2   \n",
      "4             1          original_shape_MajorAxisLength  ICC2   \n",
      "5             1  original_shape_Maximum2DDiameterColumn  ICC2   \n",
      "6             1     original_shape_Maximum2DDiameterRow  ICC2   \n",
      "..          ...                                     ...   ...   \n",
      "843           1              wavelet-LLL_ngtdm_Busyness  ICC2   \n",
      "844           1            wavelet-LLL_ngtdm_Coarseness  ICC2   \n",
      "845           1            wavelet-LLL_ngtdm_Complexity  ICC2   \n",
      "846           1              wavelet-LLL_ngtdm_Contrast  ICC2   \n",
      "847           1              wavelet-LLL_ngtdm_Strength  ICC2   \n",
      "\n",
      "              Description    ICC             F  df1  df2  pval        CI95%  \n",
      "0    Single random raters  1.000 -4.794941e+15   30   30   1.0      [1. 1.]  \n",
      "1    Single random raters  0.815  1.012100e+01   30   30   0.0  [0.65 0.91]  \n",
      "4    Single random raters  0.980  1.059390e+02   30   30   0.0  [0.96 0.99]  \n",
      "5    Single random raters  0.875  1.928500e+01   30   30   0.0  [0.68 0.95]  \n",
      "6    Single random raters  0.893  2.276900e+01   30   30   0.0  [0.72 0.95]  \n",
      "..                    ...    ...           ...  ...  ...   ...          ...  \n",
      "843  Single random raters  0.998  1.326555e+03   30   30   0.0      [1. 1.]  \n",
      "844  Single random raters  0.864  1.524200e+01   30   30   0.0  [0.73 0.93]  \n",
      "845  Single random raters  0.959  4.662600e+01   30   30   0.0  [0.92 0.98]  \n",
      "846  Single random raters  0.955  4.372100e+01   30   30   0.0  [0.91 0.98]  \n",
      "847  Single random raters  0.950  4.678500e+01   30   30   0.0  [0.88 0.98]  \n",
      "\n",
      "[812 rows x 10 columns]\n",
      "     Unnamed: 0_x                                 feature Type_x  \\\n",
      "0               1         diagnostics_Image-original_Mean   ICC2   \n",
      "1               1  original_shape_Maximum2DDiameterColumn   ICC2   \n",
      "2               1     original_shape_Maximum2DDiameterRow   ICC2   \n",
      "3               1               original_shape_MeshVolume   ICC2   \n",
      "4               1              original_shape_SurfaceArea   ICC2   \n",
      "..            ...                                     ...    ...   \n",
      "677             1          wavelet-LLL_glszm_ZoneVariance   ICC2   \n",
      "678             1              wavelet-LLL_ngtdm_Busyness   ICC2   \n",
      "679             1            wavelet-LLL_ngtdm_Coarseness   ICC2   \n",
      "680             1            wavelet-LLL_ngtdm_Complexity   ICC2   \n",
      "681             1              wavelet-LLL_ngtdm_Strength   ICC2   \n",
      "\n",
      "            Description_x  ICC_x           F_x  df1_x  df2_x  pval_x  \\\n",
      "0    Single random raters  1.000  5.095080e+15     22     22     0.0   \n",
      "1    Single random raters  0.924  2.447200e+01     22     22     0.0   \n",
      "2    Single random raters  0.941  3.344100e+01     22     22     0.0   \n",
      "3    Single random raters  0.953  5.058800e+01     22     22     0.0   \n",
      "4    Single random raters  0.958  4.626900e+01     22     22     0.0   \n",
      "..                    ...    ...           ...    ...    ...     ...   \n",
      "677  Single random raters  1.000  7.933035e+05     22     22     0.0   \n",
      "678  Single random raters  0.996  5.379530e+02     22     22     0.0   \n",
      "679  Single random raters  0.967  5.948800e+01     22     22     0.0   \n",
      "680  Single random raters  0.987  1.607790e+02     22     22     0.0   \n",
      "681  Single random raters  0.910  2.040400e+01     22     22     0.0   \n",
      "\n",
      "         CI95%_x  Unnamed: 0_y Type_y         Description_y  ICC_y  \\\n",
      "0        [1. 1.]             1   ICC2  Single random raters  1.000   \n",
      "1    [0.83 0.97]             1   ICC2  Single random raters  0.875   \n",
      "2    [0.87 0.97]             1   ICC2  Single random raters  0.893   \n",
      "3    [0.87 0.98]             1   ICC2  Single random raters  0.967   \n",
      "4    [0.91 0.98]             1   ICC2  Single random raters  0.956   \n",
      "..           ...           ...    ...                   ...    ...   \n",
      "677      [1. 1.]             1   ICC2  Single random raters  0.997   \n",
      "678  [0.99 1.  ]             1   ICC2  Single random raters  0.998   \n",
      "679  [0.93 0.99]             1   ICC2  Single random raters  0.864   \n",
      "680  [0.97 0.99]             1   ICC2  Single random raters  0.959   \n",
      "681  [0.8  0.96]             1   ICC2  Single random raters  0.950   \n",
      "\n",
      "              F_y  df1_y  df2_y  pval_y      CI95%_y  \n",
      "0   -4.794941e+15     30     30     1.0      [1. 1.]  \n",
      "1    1.928500e+01     30     30     0.0  [0.68 0.95]  \n",
      "2    2.276900e+01     30     30     0.0  [0.72 0.95]  \n",
      "3    6.461500e+01     30     30     0.0  [0.93 0.98]  \n",
      "4    5.613000e+01     30     30     0.0  [0.88 0.98]  \n",
      "..            ...    ...    ...     ...          ...  \n",
      "677  6.003910e+02     30     30     0.0  [0.99 1.  ]  \n",
      "678  1.326555e+03     30     30     0.0      [1. 1.]  \n",
      "679  1.524200e+01     30     30     0.0  [0.73 0.93]  \n",
      "680  4.662600e+01     30     30     0.0  [0.92 0.98]  \n",
      "681  4.678500e+01     30     30     0.0  [0.88 0.98]  \n",
      "\n",
      "[682 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ICC > 0.75 인 feature만 선별\n",
    "good_csv11 = csv11['ICC'] >= 0.75\n",
    "good_csv12 = csv12['ICC'] >= 0.75\n",
    "\n",
    "csv11_filter_df = csv11[good_csv11]\n",
    "csv12_filter_df = csv12[good_csv12]\n",
    "\n",
    "print(csv11_filter_df)\n",
    "print(csv12_filter_df)\n",
    "\n",
    "common_good_features_df_3 = pd.merge(csv11_filter_df, csv12_filter_df, on=\"feature\")\n",
    "\n",
    "print(common_good_features_df_3)\n",
    "\n",
    "common_good_features_list_df_3 = common_good_features_df_3[['feature']]\n",
    "common_good_features_list_3 = common_good_features_list_df_3.values.tolist()\n",
    "common_good_features_list_3.append(['Patient_ID', 'target'])\n",
    "common_good_features_list_3 = sum(common_good_features_list_3, []) # 차원 축소\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2개 이상 phase를 concat \n",
    "#data_df_train = pd.DataFrame()\n",
    "#data_df_test = pd.DataFrame()\n",
    "#data_df_train = pd.concat([csv1_ICC_filtered, csv3_ICC_filtered, csv5_ICC_filtered], axis=1) # training set ; gangnam AP + pre + T2\n",
    "#data_df_test = pd.concat([csv2_ICC_filtered, csv4_ICC_filtered, csv6_ICC_filtered], axis=1) # test set ; shinchon AP + pre + T2\n",
    "#data_df_train = pd.concat([csv3_ICC_filtered, csv5_ICC_filtered], axis=1) # training set ; gangnam pre + T2\n",
    "#data_df_test = pd.concat([csv4_ICC_filtered, csv6_ICC_filtered], axis=1) # test set ; shinchon pre + T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample augmentation using SMOTE (Synthetic Minority Oversampling TEchnique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample augmentator using SMOTE\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def smote_amplifier(input_data, input_label):\n",
    "    X = input_data\n",
    "    y = input_label\n",
    "\n",
    "    print(\"*** Pre-augmentation ***\")\n",
    "    print(y.value_counts())\n",
    "    print('\\n')\n",
    "\n",
    "    # SMOTE \n",
    "    smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "    X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "    print(\"*** Post-augmentation ***\")\n",
    "    print(y_sm.value_counts())\n",
    "    print('\\n')\n",
    "\n",
    "    return X_sm, y_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pre-augmentation ***\n",
      "1    68\n",
      "0    43\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n",
      "*** Post-augmentation ***\n",
      "0    68\n",
      "1    68\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample augmentation\n",
    "\n",
    "X_sm_train, y_sm_train = smote_amplifier(data_df_train, labels_df_train)\n",
    "#X_sm_test, y_sm_test = smote_amplifier(data_df_test, labels_df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CST (removing constant feature) 에 의한 feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "def LASSO(input_data, labels):\n",
    "    X = input_data\n",
    "    y = labels\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "                     ('scaler',StandardScaler()),\n",
    "                     ('model',Lasso())\n",
    "    ])\n",
    "    search = GridSearchCV(pipeline,\n",
    "                        {'model__alpha':np.arange(0.0,0.01,0.001)}, # alpha range를 탐색하기 위한 범위는 그때그때 임의지정 해 주자\n",
    "                        cv = 10, scoring=\"neg_mean_squared_error\",verbose=3\n",
    "                        ) # LASSO를 돌리기 위한 최적의 alpha값을 찾기 위함\n",
    "    search.fit(X_train,y_train)\n",
    "\n",
    "    print(\"Best alpha : \", search.best_params_) # best alpha 값\n",
    "    coefficients = search.best_estimator_.named_steps['model'].coef_\n",
    "    importance = np.abs(coefficients)\n",
    "\n",
    "    features = list(X_sm_train.columns)\n",
    "    features_LASSO = np.array(features)[importance == 0].tolist()\n",
    "\n",
    "    print(\"*** Total radiomics feature 갯수 ***\")\n",
    "    print(len(X.columns))\n",
    "    print(\"*** LASSO filter를 통과한 feature의 갯수 ***\")\n",
    "    print(len(X.columns)-len(features_LASSO))\n",
    "\n",
    "    data_df_LASSO = X\n",
    "\n",
    "    for feature in features_LASSO:\n",
    "        data_df_LASSO = data_df_LASSO.drop(columns=str(feature), axis=1)\n",
    "\n",
    "    return data_df_LASSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** constant filter를 통과한 feature의 갯수 ***\n",
      "1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\black\\AppData\\Local\\Temp\\ipykernel_15856\\746963978.py:25: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool)) # upper triangular 만 선택\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** highly correlation filter를 통과한 feature의 갯수 ***\n",
      "660\n",
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** Relief filter를 통과한 feature의 갯수 ***\n",
      "64\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV 1/10] END ................model__alpha=0.0;, score=-0.108 total time=   0.0s\n",
      "[CV 2/10] END ................model__alpha=0.0;, score=-0.373 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ................model__alpha=0.0;, score=-0.196 total time=   0.0s\n",
      "[CV 4/10] END ................model__alpha=0.0;, score=-0.339 total time=   0.0s\n",
      "[CV 5/10] END ................model__alpha=0.0;, score=-0.115 total time=   0.0s\n",
      "[CV 6/10] END ................model__alpha=0.0;, score=-0.331 total time=   0.0s\n",
      "[CV 7/10] END ................model__alpha=0.0;, score=-0.175 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END ................model__alpha=0.0;, score=-0.201 total time=   0.0s\n",
      "[CV 9/10] END ................model__alpha=0.0;, score=-0.202 total time=   0.0s\n",
      "[CV 10/10] END ...............model__alpha=0.0;, score=-0.087 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.535e-03, tolerance: 2.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END ..............model__alpha=0.001;, score=-0.201 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.001;, score=-0.469 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.747e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ..............model__alpha=0.001;, score=-0.249 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.001;, score=-0.239 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.721e-02, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END ..............model__alpha=0.001;, score=-0.265 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.001;, score=-0.367 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.711e-02, tolerance: 2.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e-02, tolerance: 2.045e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END ..............model__alpha=0.001;, score=-0.107 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.001;, score=-0.215 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.793e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END ..............model__alpha=0.001;, score=-0.092 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.001;, score=-0.186 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.894e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.793e-03, tolerance: 2.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END ..............model__alpha=0.002;, score=-0.192 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.002;, score=-0.419 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.468e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.780e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ..............model__alpha=0.002;, score=-0.258 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.002;, score=-0.270 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e-02, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.344e-03, tolerance: 2.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END ..............model__alpha=0.002;, score=-0.237 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.002;, score=-0.412 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.836e-03, tolerance: 2.045e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END ..............model__alpha=0.002;, score=-0.124 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.002;, score=-0.233 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.710e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.603e-03, tolerance: 2.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END ..............model__alpha=0.002;, score=-0.095 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.002;, score=-0.178 total time=   0.0s\n",
      "[CV 1/10] END ..............model__alpha=0.003;, score=-0.180 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.003;, score=-0.387 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.215e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.273e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.872e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ..............model__alpha=0.003;, score=-0.238 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.003;, score=-0.276 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.817e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.104e-03, tolerance: 2.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END ..............model__alpha=0.003;, score=-0.186 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.003;, score=-0.395 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e-03, tolerance: 2.045e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.810e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END ..............model__alpha=0.003;, score=-0.126 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.003;, score=-0.241 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.734e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.281e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.913e-03, tolerance: 2.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END ..............model__alpha=0.003;, score=-0.092 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.003;, score=-0.172 total time=   0.0s\n",
      "[CV 1/10] END ..............model__alpha=0.004;, score=-0.170 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.004;, score=-0.375 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ..............model__alpha=0.004;, score=-0.225 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.004;, score=-0.283 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.968e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END ..............model__alpha=0.004;, score=-0.182 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.004;, score=-0.377 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.521e-03, tolerance: 2.049e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.376e-03, tolerance: 2.045e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END ..............model__alpha=0.004;, score=-0.141 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.004;, score=-0.244 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.598e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.016e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END ..............model__alpha=0.004;, score=-0.079 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.004;, score=-0.160 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e-03, tolerance: 2.010e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e-02, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END ..............model__alpha=0.005;, score=-0.171 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.005;, score=-0.357 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END ..............model__alpha=0.005;, score=-0.213 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.005;, score=-0.272 total time=   0.0s\n",
      "[CV 5/10] END ..............model__alpha=0.005;, score=-0.185 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.005;, score=-0.351 total time=   0.0s\n",
      "[CV 7/10] END ..............model__alpha=0.005;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.705e-03, tolerance: 2.020e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.088e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.761e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 8/10] END ..............model__alpha=0.005;, score=-0.246 total time=   0.0s\n",
      "[CV 9/10] END ..............model__alpha=0.005;, score=-0.063 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.005;, score=-0.156 total time=   0.0s\n",
      "[CV 1/10] END ..............model__alpha=0.006;, score=-0.172 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.006;, score=-0.336 total time=   0.0s\n",
      "[CV 3/10] END ..............model__alpha=0.006;, score=-0.209 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.006;, score=-0.281 total time=   0.0s\n",
      "[CV 5/10] END ..............model__alpha=0.006;, score=-0.140 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.006;, score=-0.339 total time=   0.0s\n",
      "[CV 7/10] END ..............model__alpha=0.006;, score=-0.141 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.006;, score=-0.242 total time=   0.0s\n",
      "[CV 9/10] END ..............model__alpha=0.006;, score=-0.050 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.588e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\black\\anaconda3\\envs\\data_calc\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.297e-03, tolerance: 2.039e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 10/10] END .............model__alpha=0.006;, score=-0.151 total time=   0.0s\n",
      "[CV 1/10] END ..............model__alpha=0.007;, score=-0.176 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.007;, score=-0.309 total time=   0.0s\n",
      "[CV 3/10] END ..............model__alpha=0.007;, score=-0.208 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.007;, score=-0.267 total time=   0.0s\n",
      "[CV 5/10] END ..............model__alpha=0.007;, score=-0.131 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.007;, score=-0.335 total time=   0.0s\n",
      "[CV 7/10] END ..............model__alpha=0.007;, score=-0.143 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.007;, score=-0.237 total time=   0.0s\n",
      "[CV 9/10] END ..............model__alpha=0.007;, score=-0.050 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.007;, score=-0.155 total time=   0.0s\n",
      "[CV 1/10] END ..............model__alpha=0.008;, score=-0.179 total time=   0.0s\n",
      "[CV 2/10] END ..............model__alpha=0.008;, score=-0.290 total time=   0.0s\n",
      "[CV 3/10] END ..............model__alpha=0.008;, score=-0.204 total time=   0.0s\n",
      "[CV 4/10] END ..............model__alpha=0.008;, score=-0.266 total time=   0.0s\n",
      "[CV 5/10] END ..............model__alpha=0.008;, score=-0.137 total time=   0.0s\n",
      "[CV 6/10] END ..............model__alpha=0.008;, score=-0.331 total time=   0.0s\n",
      "[CV 7/10] END ..............model__alpha=0.008;, score=-0.140 total time=   0.0s\n",
      "[CV 8/10] END ..............model__alpha=0.008;, score=-0.224 total time=   0.0s\n",
      "[CV 9/10] END ..............model__alpha=0.008;, score=-0.053 total time=   0.0s\n",
      "[CV 10/10] END .............model__alpha=0.008;, score=-0.156 total time=   0.0s\n",
      "[CV 1/10] END model__alpha=0.009000000000000001;, score=-0.173 total time=   0.0s\n",
      "[CV 2/10] END model__alpha=0.009000000000000001;, score=-0.275 total time=   0.0s\n",
      "[CV 3/10] END model__alpha=0.009000000000000001;, score=-0.199 total time=   0.0s\n",
      "[CV 4/10] END model__alpha=0.009000000000000001;, score=-0.267 total time=   0.0s\n",
      "[CV 5/10] END model__alpha=0.009000000000000001;, score=-0.146 total time=   0.0s\n",
      "[CV 6/10] END model__alpha=0.009000000000000001;, score=-0.327 total time=   0.0s\n",
      "[CV 7/10] END model__alpha=0.009000000000000001;, score=-0.138 total time=   0.0s\n",
      "[CV 8/10] END model__alpha=0.009000000000000001;, score=-0.213 total time=   0.0s\n",
      "[CV 9/10] END model__alpha=0.009000000000000001;, score=-0.053 total time=   0.0s\n",
      "[CV 10/10] END model__alpha=0.009000000000000001;, score=-0.149 total time=   0.0s\n",
      "Best alpha :  {'model__alpha': 0.009000000000000001}\n",
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** LASSO filter를 통과한 feature의 갯수 ***\n",
      "66\n",
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** PCA filter를 통과한 feature의 갯수 ***\n",
      "64\n",
      "*** Total radiomics feature 갯수 ***\n",
      "1374\n",
      "*** FFS filter를 통과한 feature의 갯수 ***\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "X_sm_LASSO = LASSO(X_sm_train, y_sm_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_set_list = [ X_sm_LASSO]\n",
    "filtered_set_list_name = ['X_sm_LASSO']\n",
    "\n",
    "\n",
    "for i in range(len(filtered_set_list_name)):\n",
    "\n",
    "    #globals()['X_train_{}'.format(filtered_set_list_name[i])], globals()['X_test_{}'.format(filtered_set_list_name[i])], globals()['y_train_{}'.format(filtered_set_list_name[i])], globals()['y_test_{}'.format(filtered_set_list_name[i])] = \\\n",
    "                #train_test_split(filtered_set_list[i], y_sm_, test_size = 0.5, shuffle=True, random_state=42)\n",
    "\n",
    "    globals()['X_train_{}'.format(filtered_set_list_name[i])] = filtered_set_list[i]\n",
    "    globals()['y_train_{}'.format(filtered_set_list_name[i])] = y_sm_train\n",
    "    #globals()['X_test_{}'.format(filtered_set_list_name[i])] = X_sm_test.loc[:, X_sm_test.columns.isin(column_list)]\n",
    "    #globals()['y_test_{}'.format(filtered_set_list_name[i])] = y_sm_test\n",
    "    column_list = filtered_set_list[i].columns.tolist()\n",
    "    globals()['X_test_{}'.format(filtered_set_list_name[i])] = data_df_test.loc[:, data_df_test.columns.isin(column_list)]\n",
    "    globals()['y_test_{}'.format(filtered_set_list_name[i])] = labels_df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conventional Machine Learning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix, ROC, AUROC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "def validation(y_train, y_train_pred, y_test_pred_proba_01):\n",
    "    y_train = y_train\n",
    "    y_train_pred = y_train_pred\n",
    "    y_test_pred_proba_01 = y_test_pred_proba_01\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Confusion Matrix ***\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"*** ROC ***\")\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_test_pred_proba_01, )\n",
    "\n",
    "    def plot_roc_curve(fpr, tpr, label=None):\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "        plt.plot([0, 1], [0, 1], 'k--') # 대각 점선\n",
    "        plt.axis([0, 1, 0, 1])                                    # Not shown in the book\n",
    "        plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
    "        plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
    "        plt.grid(True)                                            # Not shown\n",
    "\n",
    "    plt.figure(figsize=(8, 6))                                    # Not shown\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    plt.show()\n",
    "    print(\"AUROC : \", metrics.auc(fpr, tpr))\n",
    "\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive boosting(Adab)\n",
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def SVM_clf(X_train, y_train, X_test, y_test, poly_feature_degree, LinearSVC_C):\n",
    "    X_train = X_train\n",
    "    y_train = y_train\n",
    "    X_test =  X_test\n",
    "    y_test = y_test\n",
    "    poly_feature_degree = poly_feature_degree\n",
    "    LinearSVC_C = LinearSVC_C\n",
    "\n",
    "    polynomial_svm_clf = Pipeline([\n",
    "            (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        ])\n",
    "    polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(\"*** Polynomial SVM classification validation ***\")\n",
    "    y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "    y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "    y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "    AUROC = validation(y_test, y_test_pred, y_test_pred_proba_01)\n",
    "    return AUROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple filter x Multiple classifier\n",
    "\"\"\"\n",
    "filtered_splitted_X_train = [X_train_X_sm, X_train_X_sm_CST, X_train_X_sm_Corr, X_train_X_sm_Relief, X_train_X_sm_LASSO, X_train_X_sm_PCA, X_train_X_sm_FFS]\n",
    "filtered_splitted_y_train = [y_train_X_sm, y_train_X_sm_CST, y_train_X_sm_Corr, y_train_X_sm_Relief, y_train_X_sm_LASSO, y_train_X_sm_PCA, y_train_X_sm_FFS]\n",
    "filtered_splitted_X_test = [X_test_X_sm, X_test_X_sm_CST, X_test_X_sm_Corr, X_test_X_sm_Relief, X_test_X_sm_LASSO, X_test_X_sm_PCA, X_test_X_sm_FFS]\n",
    "filtered_splitted_y_test = [y_test_X_sm, y_test_X_sm_CST, y_test_X_sm_Corr, y_test_X_sm_Relief, y_test_X_sm_LASSO, y_test_X_sm_PCA, y_test_X_sm_FFS]\n",
    "\"\"\"\n",
    "filtered_set_list = [X_sm_LASSO]\n",
    "\n",
    "filtered_splitted_X_train = [X_train_X_sm_LASSO]\n",
    "filtered_splitted_y_train = [y_train_X_sm_LASSO]\n",
    "filtered_splitted_X_test = [X_test_X_sm_LASSO]\n",
    "filtered_splitted_y_test = [y_test_X_sm_LASSO]\n",
    "\n",
    "filter_list = ['X_sm_LASSO']\n",
    "\n",
    "for i in range(len(filter_list)):\n",
    "    print(\"****************************************\")\n",
    "    print(\"     Sample set : \", filter_list[i])\n",
    "    print(\"****************************************\")\n",
    "    print(\"\\n\"\n",
    "    \n",
    "    globals()['AUROC_SVM_{}'.format(filter_list[i])] = SVM_clf(filtered_splitted_X_train[i], filtered_splitted_y_train[i], filtered_splitted_X_test[i], filtered_splitted_y_test[i], 1, 10) # [X_train, y_train, X_test, y_test, polynomial feature degree(feature 갯수 많을때 3 이상 하지 말 것), avoid misclassifying each training example]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "filter_list = ['X_sm_LASSO']\n",
    "classifier_list = ['SVM']\n",
    "\n",
    "result_df = pd.DataFrame(columns = filter_list, index = classifier_list)\n",
    "\n",
    "for i in range(len(filter_list)):\n",
    "    for j in range(len(classifier_list)):\n",
    "        result_df.at[str(classifier_list[j]), str(filter_list[i])] = globals()['AUROC_{}_{}'.format(classifier_list[j], filter_list[i])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:/Research/Liver_abscess_metastasis_radiomics/Result/20220923_Classification/test-augmentation_training-no-augmentation/\"\n",
    "save_path_file = os.path.join(save_path, \"20220929_gangnam-train_shinchon-test_AP-pre-T2.csv\")\n",
    "result_df.to_csv(save_path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM 과 RF 에서 test set 의 검정능력, predictied probability, performance matrix, ROC 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corr-SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training set tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix, ROC, AUROC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "def validation(y_train, y_train_pred, y_test_pred_proba_01):\n",
    "    y_train = y_train\n",
    "    y_train_pred = y_train_pred\n",
    "    y_test_pred_proba_01 = y_test_pred_proba_01\n",
    "    print(\"\\n\")\n",
    "    print(\"*** Confusion Matrix ***\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"*** ROC ***\")\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_test_pred_proba_01, )\n",
    "\n",
    "    \"\"\"\n",
    "    def plot_roc_curve(fpr, tpr, label=None):\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "        plt.plot([0, 1], [0, 1], 'k--') # 대각 점선\n",
    "        plt.axis([0, 1, 0, 1])                                    # Not shown in the book\n",
    "        plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
    "        plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
    "        plt.grid(True)                                            # Not shown\n",
    "\n",
    "    plt.figure(figsize=(8, 6))                                    # Not shown\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    print(\"AUROC : \", metrics.auc(fpr, tpr))\n",
    "\n",
    "\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification / test set\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Data preparation\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "\n",
    "# Binary classifier\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        (\"svm_clf\", SVC(gamma = 'auto', kernel='poly', degree = 1, coef0 = 0, C = 1, probability = True, random_state=42))\n",
    "    ])\n",
    "polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Test set prediction\n",
    "y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_test_pred_proba_01, )\n",
    "AUROC = metrics.auc(fpr_roc, tpr_roc)\n",
    "\n",
    "# Performance 계산\n",
    "CM = confusion_matrix(y_test, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(list(y_test), list(y_test_pred), labels = [0, 1]).ravel()\n",
    "TPR = TP / (TP + FN) # Sensitivity, hit rate, recall, or true positive rate\n",
    "TNR = TN / (TN + FP) # Specificity or true negative rate\n",
    "PPV = TP / (TP + FP) # Precision or positive predictive value\n",
    "NPV = TN / (TN + FN) # Negative predictive value\n",
    "FPR = FP / (FP + TN) # Fall out or false positive rate\n",
    "FNR = FN / (TP + FN) # False negative rate\n",
    "FDR = FP / (TP + FP) # False discovery rate\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN) # Overall accuracy\n",
    "\n",
    "# Performance save\n",
    "column_list = ['AUROC', 'TN', 'FP', 'FN', 'TP', 'TPR', 'TNR', 'PPV', 'NPV', 'FPR', 'FNR', 'FDR', 'ACC']\n",
    "performance_metrics_df = pd.DataFrame(columns = column_list)\n",
    "data_to_insert_df = pd.DataFrame({\n",
    "    'TN' : [TN], \n",
    "    'FP' : [FP],\n",
    "    'FN' : [FN],\n",
    "    'TP' : [TP],\n",
    "    'AUROC' : [AUROC],\n",
    "    'TPR' : [TPR],\n",
    "    'TNR' : [TNR], \n",
    "    'PPV' : [PPV], \n",
    "    'NPV' : [NPV], \n",
    "    'FPR' : [FPR], \n",
    "    'FNR' : [FNR], \n",
    "    'FDR' : [FDR], \n",
    "    'ACC' : [ACC]\n",
    "})\n",
    "performance_metrics_df = pd.concat([performance_metrics_df, data_to_insert_df], axis = 0)\n",
    "\n",
    "save_path = \"C:/Research/Liver_abscess_metastasis_radiomics/Result/20220930_Classification_metrics/\"\n",
    "save_path_file = os.path.join(save_path, \"20220930_SVM_test-set_performance_metrics_pre_T2.csv\")\n",
    "performance_metrics_df.to_csv(save_path_file)\n",
    "\n",
    "# save data for ROC curve\n",
    "fpr_df = pd.DataFrame(fpr)\n",
    "tpr_df = pd.DataFrame(tpr)\n",
    "fpr_tpr_df = pd.concat([fpr_df, tpr_df], axis = 1)\n",
    "fpr_tpr_df.columns = ['fpr', 'tpr']\n",
    "\n",
    "save_path_file_fpr = os.path.join(save_path, \"20220930_SVM_test-set_fpr_tpr_pre_T2.csv\")\n",
    "fpr_tpr_df.to_csv(save_path_file_fpr)\n",
    "\n",
    "# save data for prediction\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred)\n",
    "y_test_prob_df = pd.DataFrame(y_test_pred_proba_01)\n",
    "y_GT_pred_prob_df = pd.concat([ID_df_test, y_test, y_test_pred_df, y_test_prob_df ], axis = 1)\n",
    "y_GT_pred_prob_df.columns = ['patient_ID', 'ground_truth', 'predicted_class', ' predicted_probability']\n",
    "\n",
    "save_path_file_GT_pred_prob = os.path.join(save_path, \"20220930_SVM_test-set_GT_pred_prob_pre_T2.csv\")\n",
    "y_GT_pred_prob_df.to_csv(save_path_file_GT_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_test_pred_df = pd.DataFrame(y_test_pred)\\ny_test_prob_df = pd.DataFrame(y_test_pred_proba_01)\\ny_GT_pred_prob_df = pd.concat([ID_df_train, y_train, y_test_pred_df, y_test_prob_df ], axis = 1)\\ny_GT_pred_prob_df.columns = [\\'patient_ID\\', \\'ground_truth\\', \\'predicted_class\\', \\' predicted_probability\\']\\n\\nsave_path_file_GT_pred_prob = os.path.join(save_path, \"20220930_SVM_train-set_GT_pred_prob_pre_T2.csv\")\\ny_GT_pred_prob_df.to_csv(save_path_file_GT_pred_prob)\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polynomial SVM Classification / training set\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Data preparation\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "\n",
    "# Binary classifier\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        (\"svm_clf\", SVC(gamma = 'auto', kernel='poly', degree = 1, coef0 = 0, C = 1, probability = True, random_state=42))\n",
    "    ])\n",
    "polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Test set prediction\n",
    "y_test_pred = polynomial_svm_clf.predict(X_train)\n",
    "y_test_pred_proba = polynomial_svm_clf.predict_proba(X_train)\n",
    "y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_train, y_test_pred_proba_01, )\n",
    "AUROC = metrics.auc(fpr_roc, tpr_roc)\n",
    "\n",
    "# Performance 계산\n",
    "CM = confusion_matrix(y_train, y_test_pred)\n",
    "TN, FP, FN, TP = confusion_matrix(list(y_train), list(y_test_pred), labels = [0, 1]).ravel()\n",
    "TPR = TP / (TP + FN) # Sensitivity, hit rate, recall, or true positive rate\n",
    "TNR = TN / (TN + FP) # Specificity or true negative rate\n",
    "PPV = TP / (TP + FP) # Precision or positive predictive value\n",
    "NPV = TN / (TN + FN) # Negative predictive value\n",
    "FPR = FP / (FP + TN) # Fall out or false positive rate\n",
    "FNR = FN / (TP + FN) # False negative rate\n",
    "FDR = FP / (TP + FP) # False discovery rate\n",
    "ACC = (TP + TN) / (TP + FP + FN + TN) # Overall accuracy\n",
    "\n",
    "# Performance save\n",
    "column_list = ['AUROC', 'TN', 'FP', 'FN', 'TP', 'TPR', 'TNR', 'PPV', 'NPV', 'FPR', 'FNR', 'FDR', 'ACC']\n",
    "performance_metrics_df = pd.DataFrame(columns = column_list)\n",
    "data_to_insert_df = pd.DataFrame({\n",
    "    'TN' : [TN], \n",
    "    'FP' : [FP],\n",
    "    'FN' : [FN],\n",
    "    'TP' : [TP],\n",
    "    'AUROC' : [AUROC],\n",
    "    'TPR' : [TPR],\n",
    "    'TNR' : [TNR], \n",
    "    'PPV' : [PPV], \n",
    "    'NPV' : [NPV], \n",
    "    'FPR' : [FPR], \n",
    "    'FNR' : [FNR], \n",
    "    'FDR' : [FDR], \n",
    "    'ACC' : [ACC]\n",
    "})\n",
    "performance_metrics_df = pd.concat([performance_metrics_df, data_to_insert_df], axis = 0)\n",
    "\n",
    "save_path = \"C:/Research/Liver_abscess_metastasis_radiomics/Result/20220930_Classification_metrics/\"\n",
    "save_path_file = os.path.join(save_path, \"20220930_SVM_train-set_performance_metrics_pre_T2.csv\")\n",
    "performance_metrics_df.to_csv(save_path_file)\n",
    "\n",
    "# save data for ROC curve\n",
    "fpr_df = pd.DataFrame(fpr)\n",
    "tpr_df = pd.DataFrame(tpr)\n",
    "fpr_tpr_df = pd.concat([fpr_df, tpr_df], axis = 1)\n",
    "fpr_tpr_df.columns = ['fpr', 'tpr']\n",
    "\n",
    "save_path_file_fpr = os.path.join(save_path, \"20220930_SVM_train-set_fpr_tpr_pre_T2.csv\")\n",
    "fpr_tpr_df.to_csv(save_path_file_fpr)\n",
    "\n",
    "# save data for prediction\n",
    "\"\"\"\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred)\n",
    "y_test_prob_df = pd.DataFrame(y_test_pred_proba_01)\n",
    "y_GT_pred_prob_df = pd.concat([ID_df_train, y_train, y_test_pred_df, y_test_prob_df ], axis = 1)\n",
    "y_GT_pred_prob_df.columns = ['patient_ID', 'ground_truth', 'predicted_class', ' predicted_probability']\n",
    "\n",
    "save_path_file_GT_pred_prob = os.path.join(save_path, \"20220930_SVM_train-set_GT_pred_prob_pre_T2.csv\")\n",
    "y_GT_pred_prob_df.to_csv(save_path_file_GT_pred_prob)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification / GridSearch\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "\n",
    "column_list = ['coef0', 'C', 'poly', 'AUROC']\n",
    "AUROC_df = pd.DataFrame(columns = column_list)\n",
    "\n",
    "for idx_coef0 in range(10):\n",
    "    #print(\"coef0 :\", idx_coef0)\n",
    "    for idx_C in range(1,10):\n",
    "        #print(\"C :\", idx_C)\n",
    "        for idx_poly in range(1,3+1):\n",
    "\n",
    "\n",
    "            polynomial_svm_clf = Pipeline([\n",
    "                    (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "                    (\"svm_clf\", SVC(gamma = 'auto', kernel='poly', degree = idx_poly, coef0 = idx_coef0, C = idx_C, probability = True, random_state=42))\n",
    "                ])\n",
    "            polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "            #print(\"*** Polynomial SVM classification validation ***\")\n",
    "            y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "            y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "            y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "            \n",
    "            #print(confusion_matrix(y_test, y_test_pred))\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba_01, )\n",
    "            AUROC = metrics.auc(fpr, tpr)\n",
    "\n",
    "            data_to_insert_df = pd.DataFrame({'coef0' : [idx_coef0], 'C' : [idx_C], 'poly' : [idx_poly], 'AUROC' : [AUROC]})\n",
    "            AUROC_df = pd.concat([AUROC_df, data_to_insert_df], axis = 0)\n",
    "        \n",
    "AUROC_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"C:/Research/Liver_abscess_metastasis_radiomics/Result/20220923_Classification/\"\n",
    "save_path_file = os.path.join(save_path, \"20220929_Gridsearch_SVM.csv\")\n",
    "AUROC_df.to_csv(save_path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "poly_feature_degree = 1\n",
    "LinearSVC_C = 10\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        (\"svm_clf\", SVC(kernel='rbf', gamma = 0.0001, C = 100000, probability = True, random_state=42))\n",
    "    ])\n",
    "polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"*** Polynomial SVM classification validation ***\")\n",
    "y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "validation(y_test, y_test_pred, y_test_pred_proba_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = X_train_X_sm_Corr.to_numpy()\n",
    "y_train = y_train_X_sm_Corr.to_numpy()\n",
    "X_test =  X_test_X_sm_Corr.to_numpy()\n",
    "y_test = y_test_X_sm_Corr.to_numpy()\n",
    "poly_feature_degree = 1\n",
    "LinearSVC_C = 10\n",
    "coef0 = 1\n",
    "C = 8\n",
    "n_splits = 5\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        (\"svm_clf\", SVC(kernel='poly', degree = poly_feature_degree, coef0 = coef0, C = C, probability = True, random_state=42))\n",
    "    ])\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "y_test_pred_proba_avg = np.zeros(123,)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_test, y_test):\n",
    "    clone_clf = clone(polynomial_svm_clf)\n",
    "    X_train_folds = X_test[train_index]\n",
    "    y_train_folds = y_test[train_index]\n",
    "    X_test_fold = X_test[test_index]\n",
    "    y_test_fold = y_test[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "    y_test_pred_proba = clone_clf.predict_proba(X_test)\n",
    "    y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "    y_test_pred_proba_avg = y_test_pred_proba_avg + y_test_pred_proba_01\n",
    "\n",
    "    #print(y_test_pred_proba_01)\n",
    "\n",
    "print(\"*** Polynomial SVM classification validation ***\")\n",
    "y_test_pred_proba_avg = y_test_pred_proba_avg/n_splits\n",
    "y_test_pred = np.around(y_test_pred_proba_avg)\n",
    "validation(y_test, y_test_pred, y_test_pred_proba_avg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scores = cross_val_score(polynomial_svm_clf, X_train, y_train, cv=cv)\n",
    "#y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "#y_test_pred = cross_val_predict(polynomial_svm_clf, X_train, y_train, cv=5)\n",
    "#y_test_score = cross_val_score(polynomial_svm_clf, X_train, y_train, cv=5)\n",
    "#y_test_valid = cross_validate(polynomial_svm_clf, X_train, y_train, cv=5)\n",
    "#y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "#y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "#validation(y_test, y_test_pred, y_test_pred_proba_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification ; t\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.base import clone\n",
    "\n",
    "X_train = X_train_X_sm_Corr.to_numpy()\n",
    "y_train = y_train_X_sm_Corr.to_numpy()\n",
    "X_test =  X_test_X_sm_Corr.to_numpy()\n",
    "y_test = y_test_X_sm_Corr.to_numpy()\n",
    "poly_feature_degree = 1\n",
    "coef0 = 1\n",
    "C = 8\n",
    "n_splits = 5\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel='poly', degree = poly_feature_degree, coef0 = coef0, C = C, probability = True, random_state=42))\n",
    "    ])\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "y_test_pred_proba_avg = np.zeros(123,) # test set의 sample 숫자에 맞춰줘야 함. y_test.shape 찍어보면 알수있음.\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train):\n",
    "    clone_clf = clone(polynomial_svm_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "\n",
    "    y_test_pred_proba = clone_clf.predict_proba(X_test)\n",
    "    y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "    y_test_pred_proba_avg = y_test_pred_proba_avg + y_test_pred_proba_01\n",
    "\n",
    "\n",
    "print(\"*** Polynomial SVM classification validation ***\")\n",
    "y_test_pred_proba_avg = y_test_pred_proba_avg/n_splits\n",
    "y_test_pred = np.around(y_test_pred_proba_avg)\n",
    "validation(y_test, y_test_pred, y_test_pred_proba_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "#poly_feature_degree = 1\n",
    "LinearSVC_C = 10\n",
    "\n",
    "param_grid = [\n",
    "    {'degree' : [1, 2]}\n",
    "]\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=poly_feature_degree)), # feature 갯수 많아지면 절 대 3 이상 돌리지 말것\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"svm_clf\", SVC(kernel='linear',probability=True, random_state=42))\n",
    "        (\"svm_clf\", SVC(kernel='poly', coef0 = 1, C = 8, probability = True, random_state=42))\n",
    "    ])\n",
    "grid_search = GridSearchCV(polynomial_svm_clf, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_test, y_test)\n",
    "\n",
    "#polynomial_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#print(\"*** Polynomial SVM classification validation ***\")\n",
    "#y_test_pred = polynomial_svm_clf.predict(X_test)\n",
    "#y_test_pred_proba = polynomial_svm_clf.predict_proba(X_test)\n",
    "#y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "#validation(y_test, y_test_pred, y_test_pred_proba_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial SVM Classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Dataset 준비\n",
    "X_train = X_train_X_sm_Corr\n",
    "y_train = y_train_X_sm_Corr\n",
    "X_test =  X_test_X_sm_Corr\n",
    "y_test = y_test_X_sm_Corr\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_test =  scaler.transform(X_test)\n",
    "\n",
    "# Grid 설정\n",
    "param_grid = [\n",
    "    {'coef0' : [0, 1, 2, 3], 'C' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "]\n",
    "\n",
    "# Training\n",
    "svm_clf = SVC(kernel = 'poly', probability = True, random_state=42)\n",
    "cv = 5\n",
    "for idx in range(2, cv+1):\n",
    "    print(\"cv :\", idx)\n",
    "    grid_search = GridSearchCV(svm_clf, param_grid, cv=idx, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    #best_model.fit(X_test, y_test)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    y_test_pred_proba = best_model.predict_proba(X_test)\n",
    "    y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "    validation(y_test, y_test_pred, y_test_pred_proba_01)\n",
    "    \n",
    "    #cvres = grid_search.cv_results_\n",
    "    #for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    #    print(np.sqrt(-mean_score), params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel = 'poly', C = 7, coef0 = 1, probability = True, random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = svm_clf.predict(X_test)\n",
    "y_test_pred_proba = svm_clf.predict_proba(X_test)\n",
    "y_test_pred_proba_01 = y_test_pred_proba[:, 1]\n",
    "validation(y_test, y_test_pred, y_test_pred_proba_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X_sm\n",
    "X_sm_CST\n",
    "X_sm_Corr\n",
    "X_sm_Relief\n",
    "X_sm_LASSO\n",
    "X_sm_PCA\n",
    "X_sm_FFS\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "X_sm_filtered = X_sm\n",
    "\n",
    "Adab(X_sm_filtered, y_sm, 5,4) # [input_data, labels, n_estimator(tree갯수), cv]\n",
    "decision_tree(X_sm_filtered, y_sm, 10,4) # [input_data, labels, max_depth, cv]\n",
    "random_forest(X_sm_filtered, y_sm, 1000, 10, 4) # [input_data, labels, n_estimators, max_leaf_nodes, cv]\n",
    "KNN(X_sm_filtered, y_sm, 4) # [input_data, labels, cv]\n",
    "SGD_clf(X_sm_filtered, y_sm, 1000, 1e-3, 4) # [input_data, labels, max_iter, tolerance, cv]\n",
    "SVM_clf(X_sm_filtered, y_sm, 2, 10, 4) # [input_data, labels, polynomial feature degree(feature 갯수 많을때 3 이상 하지 말 것), avoid misclassifying each training example, cv]\n",
    "LDA(X_sm_filtered, y_sm, 4) # [input_data, labels, cv]\n",
    "QDA(X_sm_filtered, y_sm, 4) # [input_data, labels, cv]\n",
    "GNB_clf(X_sm_filtered, y_sm, 4) # [input_data, labels, cv]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pjh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c590b5c595cb72c80865821fc85b6e47bbead1a21e5e806d1e64f4e98e7020bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
